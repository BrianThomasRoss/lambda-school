{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Vector Representations\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "## 1) *Optional:* Scrape 100 Job Listings that contain the title \"Data Scientist\" from indeed.com\n",
    "\n",
    "At a minimum your final dataframe of job listings should contain\n",
    "- Job Title\n",
    "- Job Description\n",
    "\n",
    "If you choose to not to scrape the data, there is a CSV with outdated data in the directory. Remeber, if you scrape Indeed, you're helping yourself find a job. ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\"<div><div>Job Requirements:</div><ul><li><p>\\\\nConceptual understanding in Machine Learning models like Nai\\\\xc2\\\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them</p>\\\\n</li><li><p>Intermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)</p>\\\\n</li><li><p>Exposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R</p>\\\\n</li><li><p>Ability to communicate Model findings to both Technical and Non-Technical stake holders</p>\\\\n</li><li><p>Hands on experience in SQL/Hive or similar programming language</p>\\\\n</li><li><p>Must show past work via GitHub, Kaggle or any other published article</p>\\\\n</li><li><p>Master\\'s degree in Statistics/Mathematics/Computer Science or any other quant specific field.</p></li></ul><div><div><div><div><div><div>\\\\nApply Now</div></div></div></div></div></div></div><div></div>\"'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = pd.read_csv('data//job_listings.csv')\n",
    "jobs = jobs[['description', 'title']]\n",
    "jobs.description[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b Job Requirements  nConceptual understanding in Machine Learning models like Nai xc2 xa8ve Bayes  K Means  SVM  Apriori  Linear  Logistic Regression  Neural  Random Forests  Decision Trees  K NN along with hands on experience in at least 2 of them nIntermediate to expert level coding skills in Python R   Ability to write functions  clean and efficient data manipulation are mandatory for this role  nExposure to packages like NumPy  SciPy  Pandas  Matplotlib etc in Python or GGPlot2  dplyr  tidyR in R nAbility to communicate Model findings to both Technical and Non Technical stake holders nHands on experience in SQL Hive or similar programming language nMust show past work via GitHub  Kaggle or any other published article nMaster s degree in Statistics Mathematics Computer Science or any other quant specific field  nApply Now '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = jobs.description[0]\n",
    "html = re.compile(r'(<.*?>)')\n",
    "test = html.sub('', test)\n",
    "test = test.replace('\\\\', ' ')\n",
    "punct = re.compile(r'[^\\w\\d\\s]')\n",
    "test = punct.sub(' ', test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = re.findall('(?<=\\s)n\\w*.?', test)\n",
    "for i in b:\n",
    "    test = test.replace(i, ''.join(i[1:]))\n",
    "\n",
    "test = ' '.join(test.split()[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Job Requirements Conceptual understanding in Machine Learning models like Nai xc2 xa8ve Bayes K Means SVM Apriori Linear Logistic Regression Neural Random Forests Decision Trees K NN along with hands on experience in at least 2 of them Intermediate to expert level coding skills in Python R Ability to write functions clean and efficient data manipulation are mandatory for this role Exposure to packages like NumPy SciPy Pandas Matplotlib etc in Python or GGPlot2 dplyr tidyR in R Ability to communicate Model findings to both Technical and Non Technical stake holders Hands on experience in SQL Hive or similar programming language Must show past work via GitHub Kaggle or any other published article Master s degree in Statistics Mathematics Computer Science or any other quant specific field Apply Now'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wash(df):\n",
    "    df['description'] = df['description'].apply(lambda x: punct.sub('', x))\n",
    "    df['description'] = df['description'].apply(lambda x: html.sub('', x))\n",
    "    \n",
    "    df['description'] = df['description'].replace('\\\\', ' ').replace('bdiv', '')\n",
    "\n",
    "wash(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bdivdivJob RequirementsdivullipnConceptual und...</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bdivJob DescriptionbrnbrnpAs a Data Scientist ...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bdivpAs a Data Scientist you will be working o...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bdiv classjobsearchJobMetadataHeader icluxsmbm...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bulliLocation USA xe2x80x93 multiple locations...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bdivCreate various Business Intelligence Analy...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bdivpAs Spotify Premium swells to over 96M sub...</td>\n",
       "      <td>Associate Data Scientist – Premium Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bEverytown for Gun Safety the nations largest ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bulliMS in a quantitative discipline such as S...</td>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bdivpSlack is hiring experienced data scientis...</td>\n",
       "      <td>Data Scientist, Lifecyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bdivpbWho We ArebppnBlackThorn Therapeutics is...</td>\n",
       "      <td>Data Scientist, Neuroimaging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bdiv classjobsearchJobMetadataHeader icluxsmbm...</td>\n",
       "      <td>Data Scientist II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bnfosysxe2x80x93 Data amp Analytics xe2x80x93 ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bdivpAs Spotify Premium swells to over 96M sub...</td>\n",
       "      <td>Associate Data Scientist – Premium Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bdivulliExperience with guiding RampD strategy...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bdivpThe Atlantic is seeking a Data Scientist ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bdivpbTHE CHALLENGEbppnEventbrite is big bustl...</td>\n",
       "      <td>Data Scientist - Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bdiv classjobsearchJobMetadataHeader icluxsmbm...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bEverytown for Gun Safety the nations largest ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bdiv classjobsearchJobMetadataHeader icluxsmbm...</td>\n",
       "      <td>Data Analyst/Jr. Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bdiv classjobsearchJobMetadataHeader icluxsmbm...</td>\n",
       "      <td>Assistant Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bbThe ChallengebbrnAre you excited at the pros...</td>\n",
       "      <td>Data Scientist, Junior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bdivpWe are seeking a Data Scientist to join o...</td>\n",
       "      <td>Data Scientist – Personalization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bdivdivdivMotiion is a technology and data com...</td>\n",
       "      <td>Data Scientist - [Remote]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bdivdivdivpThe Scientist is responsible for th...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bAs a Data Scientist for Ads Measurement in th...</td>\n",
       "      <td>Measurement Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bdivdivdivdivpSummarypdivdivnPosted bMar 6 201...</td>\n",
       "      <td>WTE Data Science Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bdivpSlack is looking for experienced data sci...</td>\n",
       "      <td>Data Scientist, Sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bnfosysxe2x80x93 Data amp Analytics xe2x80x93 ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bdiv classjobsearchJobMetadataHeader icluxsmbm...</td>\n",
       "      <td>Data Scientist Intern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>bABOUT USnbrLark is the worlds largest AI heal...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>bdivpZenreach solves a major problem for brick...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>bdivpbPosition DescriptionbpbrnAs the Walmart ...</td>\n",
       "      <td>Staff Data Scientist - NLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>bBy trade we are a technology company but if y...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>bdivbPurpose amp Overall Relevance for the Org...</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>bdivpbabout dscoutbpnpWe are dscout At our cor...</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>bdivdivbJunior Data Scientist  Big Data EntryL...</td>\n",
       "      <td>Junior Data Scientist - Big Data (Entry-Level)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>bAbout UsnbrInterested in working for a humanc...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>bdivAir Products Inc a Fortune 500 manufacture...</td>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>bdivData Scientist brnDo you want the opportun...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>bdivbJob DescriptionbbrnpbData ScientistbppbnI...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>bdivdivdivdivdivThe Data Scientist I mines and...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>bdivpFinLocker is a leading financial data and...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>bdivpWith annual sales of 15 billion Ecolab EC...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>bdivJob DescriptionbrnbrnThe Enterprise Data S...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>bdivDescriptionnpChicago  IL IL150SW 150 S Wac...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>bdivNike Supply Chain experts ensure that ever...</td>\n",
       "      <td>Data Scientist, Supply Chain Innovation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>bdivdivThe Principal Data Scientist is respons...</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>bdivpWe are looking for a Senior Data Scientis...</td>\n",
       "      <td>Data Scientist – Content Marketing Acquisition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>bdiv classjobsearchJobMetadataHeader icluxsmbm...</td>\n",
       "      <td>Marketing Data Science Intern - Summer 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>bdivdivdivdivdivdivdivdivLos Gatos Californiad...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>bdivbiAbout the RoleibbrnbrnbLogic2020b is loo...</td>\n",
       "      <td>Data Analyst / Jr. Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>bdiv classjobsearchJobMetadataHeader icluxsmbm...</td>\n",
       "      <td>Data Scientist- Enterprise Product Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>bdivulliBachelorxe2x80x99s or Masterxe2x80x99s...</td>\n",
       "      <td>Data Scientist - Delphi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>bdivdivAt Uber we ignite opportunity by settin...</td>\n",
       "      <td>Sr Data Scientist, NLP - Customer Obsession</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>bbAbout UsbbrnWant to be part of a fantastic a...</td>\n",
       "      <td>Senior Data Science Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>bdiv classjobsearchJobMetadataHeader icluxsmbm...</td>\n",
       "      <td>2019 PhD Data Scientist Internship - Forecasti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>bdiv classjobsearchJobMetadataHeader icluxsmbm...</td>\n",
       "      <td>Data Scientist - Insurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>bppdivpSENIOR DATA SCIENTISTppnJOB DESCRIPTION...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>bdivdivdivdivdivdivpCerner Intelligence is a n...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>426 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           description  \\\n",
       "0    bdivdivJob RequirementsdivullipnConceptual und...   \n",
       "1    bdivJob DescriptionbrnbrnpAs a Data Scientist ...   \n",
       "2    bdivpAs a Data Scientist you will be working o...   \n",
       "3    bdiv classjobsearchJobMetadataHeader icluxsmbm...   \n",
       "4    bulliLocation USA xe2x80x93 multiple locations...   \n",
       "5    bdivCreate various Business Intelligence Analy...   \n",
       "6    bdivpAs Spotify Premium swells to over 96M sub...   \n",
       "7    bEverytown for Gun Safety the nations largest ...   \n",
       "8    bulliMS in a quantitative discipline such as S...   \n",
       "9    bdivpSlack is hiring experienced data scientis...   \n",
       "10   bdivpbWho We ArebppnBlackThorn Therapeutics is...   \n",
       "11   bdiv classjobsearchJobMetadataHeader icluxsmbm...   \n",
       "12   bnfosysxe2x80x93 Data amp Analytics xe2x80x93 ...   \n",
       "13   bdivpAs Spotify Premium swells to over 96M sub...   \n",
       "14   bdivulliExperience with guiding RampD strategy...   \n",
       "15   bdivpThe Atlantic is seeking a Data Scientist ...   \n",
       "16   bdivpbTHE CHALLENGEbppnEventbrite is big bustl...   \n",
       "17   bdiv classjobsearchJobMetadataHeader icluxsmbm...   \n",
       "18   bEverytown for Gun Safety the nations largest ...   \n",
       "19   bdiv classjobsearchJobMetadataHeader icluxsmbm...   \n",
       "20   bdiv classjobsearchJobMetadataHeader icluxsmbm...   \n",
       "21   bbThe ChallengebbrnAre you excited at the pros...   \n",
       "22   bdivpWe are seeking a Data Scientist to join o...   \n",
       "23   bdivdivdivMotiion is a technology and data com...   \n",
       "24   bdivdivdivpThe Scientist is responsible for th...   \n",
       "25   bAs a Data Scientist for Ads Measurement in th...   \n",
       "26   bdivdivdivdivpSummarypdivdivnPosted bMar 6 201...   \n",
       "27   bdivpSlack is looking for experienced data sci...   \n",
       "28   bnfosysxe2x80x93 Data amp Analytics xe2x80x93 ...   \n",
       "29   bdiv classjobsearchJobMetadataHeader icluxsmbm...   \n",
       "..                                                 ...   \n",
       "396  bABOUT USnbrLark is the worlds largest AI heal...   \n",
       "397  bdivpZenreach solves a major problem for brick...   \n",
       "398  bdivpbPosition DescriptionbpbrnAs the Walmart ...   \n",
       "399  bBy trade we are a technology company but if y...   \n",
       "400  bdivbPurpose amp Overall Relevance for the Org...   \n",
       "401  bdivpbabout dscoutbpnpWe are dscout At our cor...   \n",
       "402  bdivdivbJunior Data Scientist  Big Data EntryL...   \n",
       "403  bAbout UsnbrInterested in working for a humanc...   \n",
       "404  bdivAir Products Inc a Fortune 500 manufacture...   \n",
       "405  bdivData Scientist brnDo you want the opportun...   \n",
       "406  bdivbJob DescriptionbbrnpbData ScientistbppbnI...   \n",
       "407  bdivdivdivdivdivThe Data Scientist I mines and...   \n",
       "408  bdivpFinLocker is a leading financial data and...   \n",
       "409  bdivpWith annual sales of 15 billion Ecolab EC...   \n",
       "410  bdivJob DescriptionbrnbrnThe Enterprise Data S...   \n",
       "411  bdivDescriptionnpChicago  IL IL150SW 150 S Wac...   \n",
       "412  bdivNike Supply Chain experts ensure that ever...   \n",
       "413  bdivdivThe Principal Data Scientist is respons...   \n",
       "414  bdivpWe are looking for a Senior Data Scientis...   \n",
       "415  bdiv classjobsearchJobMetadataHeader icluxsmbm...   \n",
       "416  bdivdivdivdivdivdivdivdivLos Gatos Californiad...   \n",
       "417  bdivbiAbout the RoleibbrnbrnbLogic2020b is loo...   \n",
       "418  bdiv classjobsearchJobMetadataHeader icluxsmbm...   \n",
       "419  bdivulliBachelorxe2x80x99s or Masterxe2x80x99s...   \n",
       "420  bdivdivAt Uber we ignite opportunity by settin...   \n",
       "421  bbAbout UsbbrnWant to be part of a fantastic a...   \n",
       "422  bdiv classjobsearchJobMetadataHeader icluxsmbm...   \n",
       "423  bdiv classjobsearchJobMetadataHeader icluxsmbm...   \n",
       "424  bppdivpSENIOR DATA SCIENTISTppnJOB DESCRIPTION...   \n",
       "425  bdivdivdivdivdivdivpCerner Intelligence is a n...   \n",
       "\n",
       "                                                 title  \n",
       "0                                      Data scientist   \n",
       "1                                     Data Scientist I  \n",
       "2                         Data Scientist - Entry Level  \n",
       "3                                       Data Scientist  \n",
       "4                                       Data Scientist  \n",
       "5                                       Data Scientist  \n",
       "6         Associate Data Scientist – Premium Analytics  \n",
       "7                                       Data Scientist  \n",
       "8                                   Sr. Data Scientist  \n",
       "9                             Data Scientist, Lifecyle  \n",
       "10                        Data Scientist, Neuroimaging  \n",
       "11                                   Data Scientist II  \n",
       "12                                      Data Scientist  \n",
       "13        Associate Data Scientist – Premium Analytics  \n",
       "14                                      Data Scientist  \n",
       "15                                      Data Scientist  \n",
       "16                               Data Scientist - Risk  \n",
       "17                                      Data Scientist  \n",
       "18                                      Data Scientist  \n",
       "19                     Data Analyst/Jr. Data Scientist  \n",
       "20                            Assistant Data Scientist  \n",
       "21                              Data Scientist, Junior  \n",
       "22                    Data Scientist – Personalization  \n",
       "23                           Data Scientist - [Remote]  \n",
       "24                                      Data Scientist  \n",
       "25                          Measurement Data Scientist  \n",
       "26                           WTE Data Science Engineer  \n",
       "27                               Data Scientist, Sales  \n",
       "28                                      Data Scientist  \n",
       "29                               Data Scientist Intern  \n",
       "..                                                 ...  \n",
       "396                                     Data Scientist  \n",
       "397                                     Data Scientist  \n",
       "398                         Staff Data Scientist - NLP  \n",
       "399                                     Data Scientist  \n",
       "400                           Principal Data Scientist  \n",
       "401                                Lead Data Scientist  \n",
       "402     Junior Data Scientist - Big Data (Entry-Level)  \n",
       "403                                     Data Scientist  \n",
       "404                                     DATA SCIENTIST  \n",
       "405                                     Data Scientist  \n",
       "406                                     Data Scientist  \n",
       "407                                     Data Scientist  \n",
       "408                                     Data Scientist  \n",
       "409                                     Data Scientist  \n",
       "410                                     Data Scientist  \n",
       "411                                     Data Scientist  \n",
       "412            Data Scientist, Supply Chain Innovation  \n",
       "413                           Principal Data Scientist  \n",
       "414     Data Scientist – Content Marketing Acquisition  \n",
       "415        Marketing Data Science Intern - Summer 2019  \n",
       "416                              Senior Data Scientist  \n",
       "417                  Data Analyst / Jr. Data Scientist  \n",
       "418       Data Scientist- Enterprise Product Analytics  \n",
       "419                            Data Scientist - Delphi  \n",
       "420        Sr Data Scientist, NLP - Customer Obsession  \n",
       "421                       Senior Data Science Engineer  \n",
       "422  2019 PhD Data Scientist Internship - Forecasti...  \n",
       "423                         Data Scientist - Insurance  \n",
       "424                              Senior Data Scientist  \n",
       "425                                     Data Scientist  \n",
       "\n",
       "[426 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use Spacy to tokenize / clean the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer Pipe\n",
    "tokens = []\n",
    "\n",
    "for doc in tokenizer.pipe(jobs['description'], batch_size=500):\n",
    "    doc_tokens = []\n",
    "    for token in doc:\n",
    "        if (token.is_stop == False) & (token.is_punct == False):\n",
    "            doc_tokens.append(token.text.lower())\n",
    "    tokens.append(doc_tokens)\n",
    "\n",
    "jobs['tokens'] = tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemmas(text):\n",
    "\n",
    "    lemmas = []\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Something goes here :P\n",
    "    for token in doc: # punctuation already removed\n",
    "        if (token.is_stop==False) and (token.pos_!= 'PRON'):\n",
    "            lemmas.append(token.lemma_)\n",
    "    \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs['lemmas'] = jobs['description'].apply(get_lemmas)\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word frequency\n",
    "freq = pd.Series(' '.join(jobs['description']).split()).value_counts()\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_change(word_freq):\n",
    "    \"\"\"\n",
    "    stops when the pct change between descending word frequency removal is less than 1%\n",
    "    \"\"\"\n",
    "    change = 1.1\n",
    "    total = sum(word_freq.values)\n",
    "    step = 1\n",
    "    while change > .0051:\n",
    "        curr = word_freq[step]\n",
    "        prior = total - sum(word_freq.values[:step])\n",
    "        change = curr / prior\n",
    "        \n",
    "        print(word_freq[:step].index[-1], end=\"  \")\n",
    "        print(f'{change:.5f}', step, end=\"  |||\")\n",
    "        if step % 4 == 0:\n",
    "            print('\\n')\n",
    "        step +=1\n",
    "    curr = word_freq[step]\n",
    "    prior = total - sum(word_freq.values[:step])\n",
    "    change = curr / prior\n",
    "    print(word_freq[:step].index[-1], end=\"  \")\n",
    "    print(f'{change:.5f}', end=\"  |||\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "common = (freq[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs['description'] = jobs['description'].apply(lambda x:\n",
    "                                \" \".join([x for x in x.split() if x not in common]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "\n This task is not complete. \n Replace this line with your code for the task.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c298893ed071>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m##### Your Code Here #####\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n This task is not complete. \\n Replace this line with your code for the task.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mException\u001b[0m: \n This task is not complete. \n Replace this line with your code for the task."
     ]
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "raise Exception(\"\\n This task is not complete. \\n Replace this line with your code for the task.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "## 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
    " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python (U4-S1-NLP)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
