{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS9 Which Whiskey? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "whiskey = pd.read_csv('whisk-train.csv')\n",
    "whisk_test=pd.read_csv('whisk-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, col):\n",
    "    \n",
    "       \n",
    "    print('begin')\n",
    "    df['word_count'] = df[col].apply(lambda x: len(x.split()))\n",
    "\n",
    "    df['avg_word_len'] = df[col].apply(lambda x: pd\n",
    "                                                .Series(x.split()) #list to series\n",
    "                                                .str.len() # indvidual word length\n",
    "                                                .sum() / len(x.split()))\n",
    "\n",
    "    df['all_caps_freq'] = df[col].apply(lambda x: \\\n",
    "                                             len([x for x \\\n",
    "                                              in x.split() # list comprehension \\ \n",
    "                                              if (x.isupper()) # including only all uppercase words\n",
    "                                              & (len(x) > 2)]))\n",
    "\n",
    "    df['exclamatories_count'] = df[col].apply(lambda x: # sentences ending with a !\\\n",
    "                                                len(re.findall(r'[\\s\\b\\w]*[!]{1,10}', x)))\n",
    "\n",
    "\n",
    "    df['interrogatives_count'] = df[col].apply(lambda x: # sentences ending with a ? \\ \n",
    "                                                    len(re.findall(r'[\\s\\b\\w]*[?]{1,10}', x)))\n",
    "\n",
    "    # remove punctuation\n",
    "    df[col] = df[col].str.replace('[^\\w\\s]','')\n",
    "\n",
    "    #and force to lower\n",
    "    df[col] = df[col].str.lower()\n",
    "\n",
    "    # of stop words\n",
    "    stop = nlp.Defaults.stop_words    \n",
    "    df['stopwords'] = df[col].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "    \n",
    "    # drop numerics\n",
    "    df[col] = df[col].str.replace('[\\d]','')\n",
    "    \n",
    "    \n",
    "\n",
    "    return df\n",
    "\n",
    "def pct_change(df, col):\n",
    "    \"\"\"\n",
    "    stops when the pct change between descending word frequency removal is less than 1%\n",
    "    \"\"\"\n",
    "    freq = get_word_freq(df, col)\n",
    "\n",
    "    change = 1.1\n",
    "    total = sum(freq.values)\n",
    "    step = 1\n",
    "    while change > .01:\n",
    "        curr = freq[step]\n",
    "        prior = total - sum(freq.values[:step])\n",
    "        change = curr / prior\n",
    "\n",
    "        step +=1\n",
    "\n",
    "    curr = freq[step]\n",
    "    prior = total - sum(freq.values[:step])\n",
    "    change = curr / prior    \n",
    "\n",
    "    common = list(freq[:20-1].index)\n",
    "    rare = list((freq.loc[freq.values < 2]).index)\n",
    "\n",
    "    df[col] = df[col].apply(lambda x:\n",
    "                                    \" \".join([x for x in x.split() if x not in common]))\n",
    "\n",
    "    df[col] = df[col].apply(lambda x: \n",
    "                                 \" \".join([x for x in x.split() if x not in rare]))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_word_freq(df, col):\n",
    "        # word frequency\n",
    "    return pd.Series(' '.join(df[col]).split()).value_counts()\n",
    "\n",
    "def sent_analysis(df, col):\n",
    "    \n",
    "    df['sentiment'] = df[col].apply(lambda x: TextBlob(x).sentiment[0])\n",
    "    df['polarity'] = df[col].apply(lambda x: TextBlob(x).sentiment[1])\n",
    "\n",
    "    return df\n",
    "\n",
    "    \n",
    "def tokenize(df, col):\n",
    "    \n",
    "    tokenizer = Tokenizer(nlp.vocab)\n",
    "    tokens = []\n",
    "\n",
    "    for doc in tokenizer.pipe(df[col], batch_size=500):\n",
    "        doc_tokens = []\n",
    "        for token in doc:\n",
    "            if (token.is_stop == False) & (token.is_punct == False):\n",
    "                doc_tokens.append(token.text.lower())\n",
    "        tokens.append(doc_tokens)\n",
    "    \n",
    "    # apply to df\n",
    "    df['tokenized'] = tokens\n",
    "    df['tokenized'] = df['tokenized'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_lemmas(text):\n",
    "\n",
    "    lemmas = []\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Something goes here :P\n",
    "    for token in doc: # punctuation already removed\n",
    "        if (token.is_stop==False) and (token.pos_!= 'PRON'):\n",
    "            lemmas.append(token.lemma_)\n",
    "\n",
    "    return lemmas\n",
    "\n",
    "def lemmatize(df, col):\n",
    "\n",
    "    df['lemmatized'] = df[col].apply(get_lemmas)\n",
    "\n",
    "    df['lemmatized'] = df['lemmatized'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "    return df\n",
    "\n",
    "def tdidf(df, col):\n",
    "    \n",
    "    vect_word = TfidfVectorizer(max_features=20000, lowercase=True,\\\n",
    "         analyzer='word', stop_words= 'english',ngram_range=(1,3),\\\n",
    "            dtype=np.float32)\n",
    "    \n",
    "    word_vect = vect_word.fit(df[col])\n",
    "    \n",
    "    return df, word_vect\n",
    "\n",
    "def vec_PCA(df, vect, name):\n",
    "\n",
    "    pca = PCA(n_components=100)\n",
    "    \n",
    "    vec_coords = pca.fit_transform(vect.todense())\n",
    "    cols = []\n",
    "    for i in range(0, 40):\n",
    "        col = f'{name}_vec_PCA_{i}'\n",
    "        cols.append(col)\n",
    "\n",
    "\n",
    "    temp_df = pd.DataFrame(vec_coords, columns=cols)\n",
    "    df = df.join(temp_df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def k_means_vect(df, vect, name):\n",
    "\n",
    "    kms = KMeans(\n",
    "    n_clusters=12,\n",
    "    max_iter=300,\n",
    "    precompute_distances=\"auto\",\n",
    "    n_jobs=-1,\n",
    "    verbose=True)\n",
    "\n",
    "    labels = kms.fit(vect)\n",
    "\n",
    "    temp_df = pd.DataFrame(labels, columns=[f'{name}_vec_kmeans'])\n",
    "\n",
    "    df = df.join(temp_df)\n",
    "\n",
    "    return df\n",
    "\n",
    "def flag_uniques(df):\n",
    "    \n",
    "    df['cat1_flag'] = df['lemmatized'].apply(lambda x: len([x for x in x.split() if x in cat1_unique]))\n",
    "    df['cat2_flag'] = df['lemmatized'].apply(lambda x: len([x for x in x.split() if x in cat2_unique]))\n",
    "    df['cat3_flag'] = df['lemmatized'].apply(lambda x: len([x for x in x.split() if x in cat3_unique]))\n",
    "    df['cat4_flag'] = df['lemmatized'].apply(lambda x: len([x for x in x.split() if x in cat4_unique]))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def flagged(df):    \n",
    "        if df['cat1_flag'] > 0:\n",
    "            df['flag'] = 1\n",
    "        elif df['cat2_flag'] > 0:\n",
    "            df['flag'] = 2\n",
    "        elif df['cat3_flag'] > 0:\n",
    "            df['flag'] = 3\n",
    "        elif df['cat4_flag'] > 0:\n",
    "            df['flag'] = 4\n",
    "        else:\n",
    "            df['flag'] = 0\n",
    "            \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_vect(corpus):\n",
    "    \n",
    "    tfidf = TfidfVectorizer(max_features=40000, lowercase=True,\\\n",
    "     analyzer='word', stop_words= 'english',ngram_range=(1,3),\\\n",
    "        dtype=np.float32)\n",
    "\n",
    "    t_vec = tfidf.fit_transform(corpus)\n",
    "    \n",
    "    return t_vec\n",
    "\n",
    "def vec_PCA(df, vect, dims):\n",
    "\n",
    "    pca = PCA(n_components=dims, random_state=42)    \n",
    "    vec_coords = pca.fit_transform(vect.todense())\n",
    "    cols = []\n",
    "    \n",
    "    for i in range(0, dims):\n",
    "        col = f'vec_PCA_{i}'\n",
    "        cols.append(col)\n",
    "\n",
    "\n",
    "    temp_df = pd.DataFrame(vec_coords, columns=cols)\n",
    "    df = df.join(temp_df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_tsne(df, vect):\n",
    "    tsne = sklearn.manifold.TSNE(n_components=2, perplexity=30.0,\n",
    "                          early_exaggeration=12.0, learning_rate=200.0,\n",
    "                          n_iter=1000, n_iter_without_progress=300, min_grad_norm=1e-07,\n",
    "                          metric='euclidean', init='random', verbose=0,\n",
    "                          random_state=None, method='barnes_hut', angle=0.5)\n",
    "\n",
    "    train_tsne = tsne.fit_transform(vect.todense())\n",
    "    \n",
    "    cols = ['tsne_0', 'tsne_1']\n",
    "    \n",
    "    temp_df = pd.DataFrame(train_tsne, columns=cols)    \n",
    "    df = df.join(temp_df)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_df(df, col):\n",
    "    \n",
    "    df = preprocess(df, col)\n",
    "    \n",
    "    df = sent_analysis(df, col)\n",
    "    df = pct_change(df, col)\n",
    "    df = lemmatize(df, col)\n",
    "    \n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('whisk-train.csv')\n",
    "test = pd.read_csv('whisk-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin\n",
      "begin\n"
     ]
    }
   ],
   "source": [
    "train = wrangle_df(train, 'description')\n",
    "test = wrangle_df(test, 'description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>all_caps_freq</th>\n",
       "      <th>exclamatories_count</th>\n",
       "      <th>interrogatives_count</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>marriage year old bourbons mature yet very ele...</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>5.033333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.555</td>\n",
       "      <td>marriage year old bourbon mature elegant whisk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                        description  category  \\\n",
       "0   1  marriage year old bourbons mature yet very ele...         2   \n",
       "\n",
       "   word_count  avg_word_len  all_caps_freq  exclamatories_count  \\\n",
       "0          60      5.033333              0                    1   \n",
       "\n",
       "   interrogatives_count  stopwords  sentiment  polarity  \\\n",
       "0                     0         23      0.265     0.555   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  marriage year old bourbon mature elegant whisk...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for differences among classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1637, 449, 300, 200)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_1 = train.loc[train.category == 1]\n",
    "cat_2 = train.loc[train.category == 2]\n",
    "cat_3 = train.loc[train.category == 3]\n",
    "cat_4 = train.loc[train.category == 4]\n",
    "\n",
    "len(cat_1), len(cat_2), len(cat_3), len(cat_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1_words = get_word_freq(cat_1, 'lemmatized')\n",
    "cat2_words = get_word_freq(cat_2, 'lemmatized')\n",
    "cat3_words = get_word_freq(cat_3, 'lemmatized')\n",
    "cat4_words = get_word_freq(cat_4, 'lemmatized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freqs = pd.DataFrame((cat1_words, cat2_words, cat3_words, cat4_words)).T.reset_index()\n",
    "word_freqs.columns = ['word','cat1','cat2','cat3','cat4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1_unique = list(word_freqs.loc[(word_freqs['cat2'].isnull()) & (word_freqs['cat3'].isnull())\\\n",
    "                                  & (word_freqs['cat4'].isnull()) & (word_freqs['cat1'] > 2)]['word'].values)\n",
    "\n",
    "cat2_unique = list(word_freqs.loc[(word_freqs['cat1'].isnull()) & (word_freqs['cat3'].isnull())\\\n",
    "                                  & (word_freqs['cat4'].isnull()) & (word_freqs['cat2'] > 2)]['word'].values)\n",
    "\n",
    "cat3_unique = list(word_freqs.loc[(word_freqs['cat1'].isnull()) & (word_freqs['cat2'].isnull())\\\n",
    "                                  & (word_freqs['cat4'].isnull()) & (word_freqs['cat3'] > 2)]['word'].values)\n",
    "\n",
    "cat4_unique = list(word_freqs.loc[(word_freqs['cat1'].isnull()) & (word_freqs['cat2'].isnull())\\\n",
    "                                  & (word_freqs['cat3'].isnull()) & (word_freqs['cat4'] > 2)]['word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(630, 48, 45, 48)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat1_unique), len(cat2_unique), len(cat3_unique), len(cat4_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = flag_uniques(train)\n",
    "test = flag_uniques(test)\n",
    "train = train.apply(flagged, axis=1)\n",
    "test = test.apply(flagged, axis=1)\n",
    "train = train.drop(columns=['cat1_flag', 'cat2_flag', 'cat3_flag', 'cat4_flag'])\n",
    "test = test.drop(columns=['cat1_flag', 'cat2_flag', 'cat3_flag', 'cat4_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>all_caps_freq</th>\n",
       "      <th>exclamatories_count</th>\n",
       "      <th>interrogatives_count</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>marriage year old bourbons mature yet very ele...</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>5.033333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.555</td>\n",
       "      <td>marriage year old bourbon mature elegant whisk...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                        description  category  \\\n",
       "0   1  marriage year old bourbons mature yet very ele...         2   \n",
       "\n",
       "   word_count  avg_word_len  all_caps_freq  exclamatories_count  \\\n",
       "0          60      5.033333              0                    1   \n",
       "\n",
       "   interrogatives_count  stopwords  sentiment  polarity  \\\n",
       "0                     0         23      0.265     0.555   \n",
       "\n",
       "                                          lemmatized  flag  \n",
       "0  marriage year old bourbon mature elegant whisk...     0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=20000, lowercase=True,\\\n",
    "     analyzer='word', stop_words= 'english',ngram_range=(1,3),\\\n",
    "        dtype=np.float32)\n",
    "\n",
    "t_vec = tfidf.fit(train['lemmatized'])\n",
    "\n",
    "train_tfidf = t_vec.transform(train['description'])\n",
    "test_tfidf = t_vec.transform(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = vec_PCA(train, train_tfidf, 100)\n",
    "test = vec_PCA(test, test_tfidf, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_idf(text):\n",
    "    \n",
    "    l = []\n",
    "    \n",
    "    for word in text.split():\n",
    "        try:\n",
    "            w = df_idf.loc[df_idf.word == word]['idf_weights'].values[0]\n",
    "            l.append(w)\n",
    "        except Exception:\n",
    "            w = 0\n",
    "            l.append(w)\n",
    "    return np.mean(l)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abc</td>\n",
       "      <td>7.759642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aberdeenshire</td>\n",
       "      <td>7.066494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aberdeenshire distillery</td>\n",
       "      <td>7.759642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aberfeldy</td>\n",
       "      <td>6.460359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aberfeldy run</td>\n",
       "      <td>7.759642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       word  idf_weights\n",
       "0                       abc     7.759642\n",
       "1             aberdeenshire     7.066494\n",
       "2  aberdeenshire distillery     7.759642\n",
       "3                 aberfeldy     6.460359\n",
       "4             aberfeldy run     7.759642"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_idf = pd.DataFrame(t_vec.idf_, index=t_vec.get_feature_names(),columns=[\"idf_weights\"]).reset_index()\n",
    "df_idf.columns = ['word', 'idf_weights']\n",
    "df_idf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['mean_idf'] = train['lemmatized'].apply(get_mean_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['mean_idf'] = test['lemmatized'].apply(get_mean_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = sklearn.manifold.TSNE(n_components=2, perplexity=30.0,\n",
    "                      early_exaggeration=12.0, learning_rate=200.0,\n",
    "                      n_iter=1000, n_iter_without_progress=300, min_grad_norm=1e-07,\n",
    "                      metric='euclidean', init='random', verbose=0,\n",
    "                      random_state=None, method='barnes_hut', angle=0.5)\n",
    "\n",
    "train_tsne = tsne.fit_transform(train_tfidf.toarray())\n",
    "test_tsne = tsne.fit_transform(test_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['tsne_0', 'tsne_1']\n",
    "    \n",
    "# temp_df1 = pd.DataFrame(train_tsne, columns=cols)\n",
    "# temp_df2 = pd.DataFrame(test_tsne, columns=cols)\n",
    "\n",
    "train = train.join(temp_df1)\n",
    "test = test.join(temp_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = vect.build_tokenizer()\n",
    "stop_words = vect.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform. 'Pipeline(memory=None,\n     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n...nts=2, n_iter=1000, n_iter_without_progress=300,\n   perplexity=30.0, random_state=None, verbose=0))])' (type <class 'sklearn.pipeline.Pipeline'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-123-262bb48507a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'squared_hinge'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mpipe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lsi'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlsi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'clf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0msvc_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\U4-S1-NLP-DS9\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, steps, memory)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\U4-S1-NLP-DS9\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m                 raise TypeError(\"All intermediate steps should be \"\n\u001b[0;32m    166\u001b[0m                                 \u001b[1;34m\"transformers and implement fit and transform.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m                                 \" '%s' (type %s) doesn't\" % (t, type(t)))\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[1;31m# We allow last estimator to be None as an identity transformation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform. 'Pipeline(memory=None,\n     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n...nts=2, n_iter=1000, n_iter_without_progress=300,\n   perplexity=30.0, random_state=None, verbose=0))])' (type <class 'sklearn.pipeline.Pipeline'>) doesn't"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'lsi__svd__n_components': [200 ,225],\n",
    "    'lsi__vect__max_df':[.9, .99],\n",
    "    'lsi__vect__min_df':[3, 5],\n",
    "    'lsi__vect__stop_words': ['english'],\n",
    "    'lsi__vect__tokenizer': [None],\n",
    "    'clf__C':[0.8, 1]\n",
    "}\n",
    "\n",
    "\n",
    "tsne = sklearn.manifold.TSNE(n_components=2, perplexity=30.0,\n",
    "                      early_exaggeration=12.0, learning_rate=200.0,\n",
    "                      n_iter=1000, n_iter_without_progress=300, min_grad_norm=1e-07,\n",
    "                      metric='euclidean', init='random', verbose=0,\n",
    "                      random_state=None, method='barnes_hut', angle=0.5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "svd = TruncatedSVD(algorithm='randomized',\n",
    "                   n_iter=10,)\n",
    "vect = TfidfVectorizer(ngram_range=(1,3))\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd), ('tsne', tsne)])\n",
    "\n",
    "\n",
    "clf = LinearSVC(loss='squared_hinge', max_iter=200)\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', clf)])\n",
    "\n",
    "svc_search = GridSearchCV(pipe, parameters, cv=5, n_jobs=-1, verbose=10)\n",
    "svc_search.fit(whiskey['description'],whiskey['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2586, 112)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 1,\n",
       " 'lsi__svd__n_components': 225,\n",
       " 'lsi__vect__max_df': 0.9,\n",
       " 'lsi__vect__min_df': 3,\n",
       " 'lsi__vect__stop_words': 'english',\n",
       " 'lsi__vect__tokenizer': <function sklearn.feature_extraction.text.VectorizerMixin.build_tokenizer.<locals>.<lambda>(doc)>}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4, 1, 1, 1, 1, 1, 2, 1, 4, 4, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1,\n",
       "       1, 1, 4, 1, 1, 1, 3, 1, 4, 2, 1, 1, 1, 1, 1, 3, 4, 3, 2, 1, 1, 1,\n",
       "       1, 1, 1, 2, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 4,\n",
       "       2, 1, 1, 1, 1, 3, 1, 1, 4, 1, 3, 2, 1, 1, 4, 2, 2, 1, 1, 3, 2, 4,\n",
       "       1, 3, 1, 1, 1, 1, 1, 4, 1, 1, 4, 3, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2,\n",
       "       3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 2, 2, 4, 1, 1,\n",
       "       1, 1, 3, 2, 1, 1, 1, 1, 1, 3, 2, 1, 1, 3, 4, 1, 1, 1, 3, 1, 1, 1,\n",
       "       1, 1, 2, 1, 1, 1, 1, 1, 4, 1, 1, 1, 3, 1, 2, 2, 1, 3, 3, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 4, 1, 3, 1, 4, 1, 1, 2, 2, 1, 1,\n",
       "       2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 4, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1,\n",
       "       1, 4, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 3,\n",
       "       2, 2, 1, 3, 1, 3, 3, 3, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 3, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3, 4, 1, 1, 1, 3,\n",
       "       2, 1], dtype=int64)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_search.predict(whisk_test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_lin_svc = svc_search.predict(whisk_test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_rfc = grid_search.predict(whisk_test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'category'\n",
    "\n",
    "features = train.columns.to_list()\n",
    "features.remove(target)\n",
    "features.remove('lemmatized')\n",
    "features.remove('description')\n",
    "\n",
    "X = train[features]\n",
    "y = train[[target]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### column transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(\n",
    "    [('lemmatized_tfidf', TfidfVectorizer(max_features = 20000, stop_words = 'english', ngram_range=(1,3)), 'lemmatized'),\n",
    "#     ('tokenized_tfidf', TfidfVectorizer(max_features = 20000, stop_words = 'english', ngram_range=(1,3)), 'tokenized'),\n",
    "    ('description_tfidf', TfidfVectorizer(max_features = 20000, stop_words = 'english', ngram_range=(1,3)), 'description')\n",
    "    ],\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "models = [LogisticRegression(solver='lbfgs', max_iter=1000),\n",
    "          DecisionTreeClassifier(max_depth=3),\n",
    "          DecisionTreeClassifier(max_depth=None),\n",
    "          RandomForestClassifier(max_depth=3, n_estimators=50, n_jobs=-1, random_state=42),\n",
    "          RandomForestClassifier(max_depth=None, n_estimators=50, n_jobs=-1, random_state=42),\n",
    "          XGBClassifier(max_depth=3, n_estimators=50, n_jobs=-1, random_state=42)\n",
    "         ]\n",
    "\n",
    "for model in models:\n",
    "    print(model, '\\n')\n",
    "    score = cross_val_score(model, X, y, scoring='accuracy', cv=5).mean()\n",
    "    print('Cross_Validation Accuracy:', score, '\\n', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = {'C': [0.1, 0.5, 1, 5, 10, 50, 100],\n",
    "                   'solver': ['lbfgs', 'liblinear']}\n",
    "log_search = GridSearchCV(LogisticRegression(), tuned_parameters, cv=3, scoring=\"accuracy\")\n",
    "log_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = test.drop(columns='lemmatized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds = log_search.predict(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.DataFrame({'id': whisk_test['id'], 'category':preds_lin_svc})\n",
    "for i in range(0, 5):\n",
    "    preds = grid_search.predict(whisk_test['description'])\n",
    "    p = pd.DataFrame({f'pred_{i}': preds})\n",
    "    \n",
    "    master = master.join(p)\n",
    "master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 740,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9617169373549884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      1.00      0.99      1637\n",
      "           2       0.95      0.91      0.93       449\n",
      "           3       0.89      0.89      0.89       300\n",
      "           4       0.99      0.90      0.94       200\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2586\n",
      "   macro avg       0.95      0.92      0.94      2586\n",
      "weighted avg       0.96      0.96      0.96      2586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy %s' % accuracy_score(preds, whiskey['category']))\n",
    "print(classification_report(whiskey['category'], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_svc_1 = pd.DataFrame({'id': whisk_test['id'], 'category':preds_lin_svc})\n",
    "# preds_rfc = pd.DataFrame({'id': whisk_test['id'], 'category':preds_rfc})\n",
    "# pred_log = pd.DataFrame({'id': whisk_test['id'], 'category':log_preds})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_ids = test[['cat1_flag', 'cat2_flag', 'cat3_flag', 'cat4_flag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flagged(df):    \n",
    "        if df['cat1_flag'] > 0:\n",
    "            df['flag'] = 1\n",
    "        elif df['cat2_flag'] > 0:\n",
    "            df['flag'] = 2\n",
    "        elif df['cat3_flag'] > 0:\n",
    "            df['flag'] = 3\n",
    "        elif df['cat4_flag'] > 0:\n",
    "            df['flag'] = 4\n",
    "        else:\n",
    "            df['flag'] = 0\n",
    "            \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_ids = flag_ids.apply(flagged, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pred_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.join(pd.DataFrame(pred_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame({'id': test['id'], 'rfc': preds_rfc, 'svc': preds_lin_svc, 'log': log_preds})\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.join(flag_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(preds.loc[(preds['flag'] != preds['svc']) & (preds['flag'] != 0) ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputed(df):\n",
    "    \n",
    "        df['category'] = df['svc'] \n",
    "        \n",
    "        if df['flag'] > 0:\n",
    "            df['category'] = df['flag']\n",
    "        else:\n",
    "            df['category'] = df['svc']            \n",
    "            \n",
    "        return df\n",
    "\n",
    "preds['category'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.apply(imputed, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-c66c8509e20f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_svc_1 = pd.DataFrame({'id': whisk_test['id'], 'category':preds_lin_svc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_svc_1.to_csv('linsvc3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (U4-S1-NLP)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
